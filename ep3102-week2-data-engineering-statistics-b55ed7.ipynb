{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":169835,"sourceType":"datasetVersion","datasetId":74977},{"sourceId":1508992,"sourceType":"datasetVersion","datasetId":888463},{"sourceId":8469272,"sourceType":"datasetVersion","datasetId":5049828},{"sourceId":12687167,"sourceType":"datasetVersion","datasetId":8017557}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nimport re\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom scipy.stats import boxcox\nfrom scipy.stats import yeojohnson\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:13.552650Z","iopub.execute_input":"2025-08-12T18:36:13.553593Z","iopub.status.idle":"2025-08-12T18:36:13.567699Z","shell.execute_reply.started":"2025-08-12T18:36:13.553565Z","shell.execute_reply":"2025-08-12T18:36:13.566830Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Week 2 Briefing\nThis week, our goal is to learn the basics of statistical tools required for data engineering. There are four modules as part of this week's learning goals:\n* Data cleaning\n* Statistical queries on dataset\n* Data visualization\n* Data transformation","metadata":{}},{"cell_type":"markdown","source":"# Module 1: Data cleaning\nPackages used: pandas, numpy, re, sklearn.impute\nSteps: EDA, Missing data handling, removing duplicates, formatting and data type, string cleaning and standardization, outliers, validation, text cleaning.","metadata":{}},{"cell_type":"code","source":"# Load dataset\ndf = pd.read_csv('/kaggle/input/dirty-dataset-to-practice-data-cleaning/my_file (1).csv')\ndf.head() #preview first few rows to understand the structure\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:13.577607Z","iopub.execute_input":"2025-08-12T18:36:13.577941Z","iopub.status.idle":"2025-08-12T18:36:13.593202Z","shell.execute_reply.started":"2025-08-12T18:36:13.577917Z","shell.execute_reply":"2025-08-12T18:36:13.592244Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.info() #concise summary of the dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:13.594603Z","iopub.execute_input":"2025-08-12T18:36:13.594894Z","iopub.status.idle":"2025-08-12T18:36:13.604450Z","shell.execute_reply.started":"2025-08-12T18:36:13.594863Z","shell.execute_reply":"2025-08-12T18:36:13.603643Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.columns #list the columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:13.605383Z","iopub.execute_input":"2025-08-12T18:36:13.605898Z","iopub.status.idle":"2025-08-12T18:36:13.621532Z","shell.execute_reply.started":"2025-08-12T18:36:13.605869Z","shell.execute_reply":"2025-08-12T18:36:13.620661Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Exploratory data analysis: identify missing values, duplicates, data types, summary\nprint(df.isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:13.623117Z","iopub.execute_input":"2025-08-12T18:36:13.623363Z","iopub.status.idle":"2025-08-12T18:36:13.637414Z","shell.execute_reply.started":"2025-08-12T18:36:13.623333Z","shell.execute_reply":"2025-08-12T18:36:13.636595Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df.duplicated())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:13.638249Z","iopub.execute_input":"2025-08-12T18:36:13.638462Z","iopub.status.idle":"2025-08-12T18:36:13.652470Z","shell.execute_reply.started":"2025-08-12T18:36:13.638446Z","shell.execute_reply":"2025-08-12T18:36:13.651562Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df.describe(include='all'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:13.653396Z","iopub.execute_input":"2025-08-12T18:36:13.653788Z","iopub.status.idle":"2025-08-12T18:36:13.685060Z","shell.execute_reply.started":"2025-08-12T18:36:13.653762Z","shell.execute_reply":"2025-08-12T18:36:13.684226Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df.dtypes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:13.685973Z","iopub.execute_input":"2025-08-12T18:36:13.686247Z","iopub.status.idle":"2025-08-12T18:36:13.700926Z","shell.execute_reply.started":"2025-08-12T18:36:13.686221Z","shell.execute_reply":"2025-08-12T18:36:13.700130Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#text cleaning using anonymous function lambda\ndf[\"Ref.\"]= df[\"Ref.\"].apply(lambda x : re.sub(r\"[^a-zA-Z0-9]\" , \"\" , x))\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:13.702828Z","iopub.execute_input":"2025-08-12T18:36:13.703102Z","iopub.status.idle":"2025-08-12T18:36:13.727623Z","shell.execute_reply.started":"2025-08-12T18:36:13.703080Z","shell.execute_reply":"2025-08-12T18:36:13.726761Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print([{col} for col in df.columns])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:13.728539Z","iopub.execute_input":"2025-08-12T18:36:13.728825Z","iopub.status.idle":"2025-08-12T18:36:13.741194Z","shell.execute_reply.started":"2025-08-12T18:36:13.728781Z","shell.execute_reply":"2025-08-12T18:36:13.740302Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#remove unwarranted spaces\ndf.columns = df.columns.str.replace('\\xa0', ' ', regex=False)\nprint([col for col in df.columns])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:13.761570Z","iopub.execute_input":"2025-08-12T18:36:13.761933Z","iopub.status.idle":"2025-08-12T18:36:13.767660Z","shell.execute_reply.started":"2025-08-12T18:36:13.761907Z","shell.execute_reply":"2025-08-12T18:36:13.766724Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#cleaning text\ndef clean_text(text):\n    text = re.sub(r\"\\[\\s*.*?\\s*\\]\", \"\" , text)\n    text = re.sub(r\"[^a-zA-Z0-9]\", \"\" , text)\n    return text \ncolumns = [\"Actual gross\" , \"Actual gross(in 2022 dollars)\" , \"Average gross\"]\nfor column in columns:\n    df[column] = df[column].apply(clean_text)\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:13.769388Z","iopub.execute_input":"2025-08-12T18:36:13.769595Z","iopub.status.idle":"2025-08-12T18:36:13.797522Z","shell.execute_reply.started":"2025-08-12T18:36:13.769579Z","shell.execute_reply":"2025-08-12T18:36:13.796579Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#cleaning texts\ndef clean_peak(text):\n    if not pd.isna(text):\n        text =  re.sub(r\"\\[\\s*.*?\\s*\\]\", \"\" , text)\n    return text\ncolumns = [\"Peak\" , \"All Time Peak\"]\nfor column in columns:\n    df[column] = df[column].apply(clean_peak)\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:13.798327Z","iopub.execute_input":"2025-08-12T18:36:13.798533Z","iopub.status.idle":"2025-08-12T18:36:13.830463Z","shell.execute_reply.started":"2025-08-12T18:36:13.798517Z","shell.execute_reply":"2025-08-12T18:36:13.829353Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#remove wierd characters from the strings\ndef clean_title(text):\n    text =  re.sub(r\"[^a-zA-Z ]\", \"\" , text)\n    return text\ndf[\"Tour title\"] = df[\"Tour title\"].apply(clean_title)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:13.831269Z","iopub.execute_input":"2025-08-12T18:36:13.831548Z","iopub.status.idle":"2025-08-12T18:36:13.836855Z","shell.execute_reply.started":"2025-08-12T18:36:13.831528Z","shell.execute_reply":"2025-08-12T18:36:13.835978Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:13.839167Z","iopub.execute_input":"2025-08-12T18:36:13.839401Z","iopub.status.idle":"2025-08-12T18:36:13.863019Z","shell.execute_reply.started":"2025-08-12T18:36:13.839383Z","shell.execute_reply":"2025-08-12T18:36:13.862122Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Fixing inconsistent data\ndf[\"Ref.\"] = df[\"Ref.\"].replace(\"1516\" , \"16\")\ndf[\"Ref.\"] = df[\"Ref.\"].replace(\"d\" , \"5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:13.863782Z","iopub.execute_input":"2025-08-12T18:36:13.864055Z","iopub.status.idle":"2025-08-12T18:36:13.877990Z","shell.execute_reply.started":"2025-08-12T18:36:13.864035Z","shell.execute_reply":"2025-08-12T18:36:13.877132Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:13.878957Z","iopub.execute_input":"2025-08-12T18:36:13.879241Z","iopub.status.idle":"2025-08-12T18:36:13.906079Z","shell.execute_reply.started":"2025-08-12T18:36:13.879221Z","shell.execute_reply":"2025-08-12T18:36:13.905181Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Fixing numerical columns data type; convert to float\nnumeric_cols = [\"Actual gross\" , \"Actual gross(in 2022 dollars)\" \n                , \"Average gross\" , \"Shows\" , \"Ref.\" , \"Peak\" , \"All Time Peak\"]\nfor cols in numeric_cols :\n    df[cols] = df[cols].astype(\"float\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:13.906991Z","iopub.execute_input":"2025-08-12T18:36:13.907313Z","iopub.status.idle":"2025-08-12T18:36:13.923931Z","shell.execute_reply.started":"2025-08-12T18:36:13.907292Z","shell.execute_reply":"2025-08-12T18:36:13.922966Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:13.924746Z","iopub.execute_input":"2025-08-12T18:36:13.925017Z","iopub.status.idle":"2025-08-12T18:36:13.956085Z","shell.execute_reply.started":"2025-08-12T18:36:13.924997Z","shell.execute_reply":"2025-08-12T18:36:13.955201Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#drop columns with too many missing values\ndf = df.drop([\"All Time Peak\" , \"Peak\"] , axis =1)\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:13.956925Z","iopub.execute_input":"2025-08-12T18:36:13.957154Z","iopub.status.idle":"2025-08-12T18:36:13.985055Z","shell.execute_reply.started":"2025-08-12T18:36:13.957136Z","shell.execute_reply":"2025-08-12T18:36:13.984148Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Final validation\nprint(df.isnull().sum())\nprint(df.describe(include='all'))\nprint(df.head())\n\n# Save cleaned version\ndf.to_csv('dirty_dataset_cleaned.csv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:13.985944Z","iopub.execute_input":"2025-08-12T18:36:13.986653Z","iopub.status.idle":"2025-08-12T18:36:14.023550Z","shell.execute_reply.started":"2025-08-12T18:36:13.986622Z","shell.execute_reply":"2025-08-12T18:36:14.022786Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Module 2: Querying data, statistical properties and error\nPackages used: pandas","metadata":{}},{"cell_type":"code","source":"# Load data \ndf = pd.read_csv(\"/kaggle/input/students-performance-in-exams/StudentsPerformance.csv\")\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:14.024304Z","iopub.execute_input":"2025-08-12T18:36:14.024505Z","iopub.status.idle":"2025-08-12T18:36:14.037957Z","shell.execute_reply.started":"2025-08-12T18:36:14.024489Z","shell.execute_reply":"2025-08-12T18:36:14.037165Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Exploration: looking for numerical data\nnumeric_cols = ['math score', 'reading score', 'writing score']\ndf[numeric_cols].describe()\n\n#Exercise 1: Add a new column that computes average score of a student across the three subjects","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:14.038726Z","iopub.execute_input":"2025-08-12T18:36:14.039067Z","iopub.status.idle":"2025-08-12T18:36:14.058927Z","shell.execute_reply.started":"2025-08-12T18:36:14.039045Z","shell.execute_reply":"2025-08-12T18:36:14.057874Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Exercise 1\n\ndf = pd.read_csv(\"/kaggle/input/students-performance-in-exams/StudentsPerformance.csv\")\n\ndf['average score'] = df[['math score', 'reading score', 'writing score']].mean(axis=1)\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:14.063732Z","iopub.execute_input":"2025-08-12T18:36:14.064035Z","iopub.status.idle":"2025-08-12T18:36:14.080792Z","shell.execute_reply.started":"2025-08-12T18:36:14.064011Z","shell.execute_reply":"2025-08-12T18:36:14.080044Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Mean, mode and median\nprint(\"Mean Math Score:\", df['math score'].mean())\nprint(\"Median Math Score:\", df['math score'].median())\nprint(\"Mode Math Score:\", df['math score'].mode()[0])\n\n#Exercise 2: Compute mean, median, mode for reading and writing scores.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:14.081625Z","iopub.execute_input":"2025-08-12T18:36:14.081931Z","iopub.status.idle":"2025-08-12T18:36:14.087424Z","shell.execute_reply.started":"2025-08-12T18:36:14.081912Z","shell.execute_reply":"2025-08-12T18:36:14.086566Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Exercise 2: \n\n# Reading\nprint(\"Mean Reading Score:\", df['reading score'].mean())\nprint(\"Median Reading Score:\", df['reading score'].median())\nprint(\"Mode Reading Score:\", df['reading score'].mode()[0])\n\n# Writing\nprint(\"Mean Writing Score:\", df['writing score'].mean())\nprint(\"Median Writing Score:\", df['writing score'].median())\nprint(\"Mode Writing Score:\", df['writing score'].mode()[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:14.088546Z","iopub.execute_input":"2025-08-12T18:36:14.088790Z","iopub.status.idle":"2025-08-12T18:36:14.111110Z","shell.execute_reply.started":"2025-08-12T18:36:14.088772Z","shell.execute_reply":"2025-08-12T18:36:14.110229Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['math score'][1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:14.112118Z","iopub.execute_input":"2025-08-12T18:36:14.112454Z","iopub.status.idle":"2025-08-12T18:36:14.129519Z","shell.execute_reply.started":"2025-08-12T18:36:14.112428Z","shell.execute_reply":"2025-08-12T18:36:14.128588Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Measuring spread of data\nprint(\"Standard Deviation (Math):\", df['math score'].std())\nprint(\"Variance (Math):\", df['math score'].var())\nprint(\"Range (Math):\", df['math score'].max() - df['math score'].min())\n\n#Exercise 3: Repeat above steps for other subjects. What do you infer about subject difficulty?","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:14.130445Z","iopub.execute_input":"2025-08-12T18:36:14.130782Z","iopub.status.idle":"2025-08-12T18:36:14.145356Z","shell.execute_reply.started":"2025-08-12T18:36:14.130754Z","shell.execute_reply":"2025-08-12T18:36:14.144463Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Exercise 3:\n\n# Reading\nprint(\"Std Dev (Reading):\", df['reading score'].std())\nprint(\"Variance (Reading):\", df['reading score'].var())\nprint(\"Range (Reading):\", df['reading score'].max() - df['reading score'].min())\n\n# Writing\nprint(\"Std Dev (Writing):\", df['writing score'].std())\nprint(\"Variance (Writing):\", df['writing score'].var())\nprint(\"Range (Writing):\", df['writing score'].max() - df['writing score'].min())\n\n# Most difficult subject (highest std deviation)\nstd_dict = {\n    'Math': df['math score'].std(),\n    'Reading': df['reading score'].std(),\n    'Writing': df['writing score'].std()\n}\n\nmost_difficult = max(std_dict, key=std_dict.get)\nprint(\"Most Difficult Subject:\", most_difficult)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:14.146415Z","iopub.execute_input":"2025-08-12T18:36:14.146743Z","iopub.status.idle":"2025-08-12T18:36:14.165435Z","shell.execute_reply.started":"2025-08-12T18:36:14.146686Z","shell.execute_reply":"2025-08-12T18:36:14.164637Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Module 3: Data visualization \nPackages used: seaborn, matplotlib ","metadata":{}},{"cell_type":"code","source":"sns.histplot(df['math score'], kde=True)\nplt.axvline(df['math score'].mean(), color='red', linestyle='--', label='Mean')\nplt.axvline(df['math score'].median(), color='green', linestyle='--', label='Median')\nplt.legend()\nplt.title(\"Distribution of Math Scores\")\nplt.show()\n\n#Exercise 4: Repeat for reading and writing scores","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:14.166352Z","iopub.execute_input":"2025-08-12T18:36:14.166649Z","iopub.status.idle":"2025-08-12T18:36:14.449553Z","shell.execute_reply.started":"2025-08-12T18:36:14.166625Z","shell.execute_reply":"2025-08-12T18:36:14.448756Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Exercise 4: \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.boxplot(x='test preparation course', y='math score', hue='gender', data=df)\nplt.title(\"Math Scores by Test Prep & Gender\", fontsize=14)\nplt.xlabel(\"Test Preparation Course\")\nplt.ylabel(\"Math Score\")\nplt.legend(title=\"Gender\", loc=\"upper right\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:14.450665Z","iopub.execute_input":"2025-08-12T18:36:14.451312Z","iopub.status.idle":"2025-08-12T18:36:14.632153Z","shell.execute_reply.started":"2025-08-12T18:36:14.451278Z","shell.execute_reply":"2025-08-12T18:36:14.631319Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Comarisons using visualization\nsns.boxplot(x='test preparation course', y='math score', data=df)\nplt.title(\"Math Score vs Test Preparation\")\n\n#Exercise 5: Try changing legends, title, axis labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:14.633128Z","iopub.execute_input":"2025-08-12T18:36:14.633461Z","iopub.status.idle":"2025-08-12T18:36:14.802686Z","shell.execute_reply.started":"2025-08-12T18:36:14.633439Z","shell.execute_reply":"2025-08-12T18:36:14.801872Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Exercise 5: Plot distributions other than Gaussian and Poisson\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import binom, expon\n\n# Binomial Distribution\nx = np.arange(0, 21)\np = 0.5\nbinomial_pmf = binom.pmf(x, n=20, p=p)\nplt.bar(x, binomial_pmf)\nplt.title(\"Binomial Distribution (n=20, p=0.5)\")\nplt.show()\n\n# Exponential Distribution\nx_exp = np.linspace(0, 10, 100)\nexp_pdf = expon.pdf(x_exp, scale=1)\nplt.plot(x_exp, exp_pdf, color='green')\nplt.title(\"Exponential Distribution (λ=1)\")\nplt.show()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:14.803662Z","iopub.execute_input":"2025-08-12T18:36:14.804536Z","iopub.status.idle":"2025-08-12T18:36:15.126734Z","shell.execute_reply.started":"2025-08-12T18:36:14.804508Z","shell.execute_reply":"2025-08-12T18:36:15.125955Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.displot(df['math score'], kde=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:15.127728Z","iopub.execute_input":"2025-08-12T18:36:15.128063Z","iopub.status.idle":"2025-08-12T18:36:15.419657Z","shell.execute_reply.started":"2025-08-12T18:36:15.128022Z","shell.execute_reply":"2025-08-12T18:36:15.418844Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Module 3.1: Generating a normal distribution \n* np.random.normal(loc=mu, scale=sigma, size=n) generates random numbers from a normal (Gaussian) distribution.\n* plt.hist(..., density=True) makes the histogram show a probability density, not just raw counts.\n* The red line overlays the theoretical probability density function (PDF) for comparison.","metadata":{}},{"cell_type":"code","source":"# Parameters for the normal distribution\nmu = 0       # Mean\nsigma = 1    # Standard deviation\nn = 10000    # Number of samples\n\n# Generate random samples from a normal distribution\ndata = np.random.normal(loc=mu, scale=sigma, size=n)\n\n# Plot histogram of the data\nplt.figure(figsize=(8, 5))\nplt.hist(data, bins=50, density=True, alpha=0.6, color='skyblue', edgecolor='black')\n\n# Plot the theoretical normal distribution curve\nfrom scipy.stats import norm\nx = np.linspace(mu - 4*sigma, mu + 4*sigma, 1000)\nplt.plot(x, norm.pdf(x, mu, sigma), 'r', label='Theoretical PDF')\n\nplt.title(\"Generated Normal Distribution (μ=0, σ=1)\")\nplt.xlabel(\"Value\")\nplt.ylabel(\"Probability Density\")\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:15.420441Z","iopub.execute_input":"2025-08-12T18:36:15.420643Z","iopub.status.idle":"2025-08-12T18:36:15.694214Z","shell.execute_reply.started":"2025-08-12T18:36:15.420626Z","shell.execute_reply":"2025-08-12T18:36:15.693287Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Module 3.2: Generating a theoretical poisson/gaussian distribution","metadata":{}},{"cell_type":"code","source":"#Poisson distribution\nfrom scipy.stats import poisson\n\nx = np.arange(0, 20)\npmf = poisson.pmf(x, mu=5)\nplt.bar(x, pmf)\nplt.title(\"Poisson Distribution (μ=5)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:15.695290Z","iopub.execute_input":"2025-08-12T18:36:15.695541Z","iopub.status.idle":"2025-08-12T18:36:15.926080Z","shell.execute_reply.started":"2025-08-12T18:36:15.695521Z","shell.execute_reply":"2025-08-12T18:36:15.925292Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Gaussian distribution\npdf=norm.pdf(x,mu,sigma)\nplt.bar(x,pdf)\nplt.title(\"Gaussian distribution\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:15.927062Z","iopub.execute_input":"2025-08-12T18:36:15.927360Z","iopub.status.idle":"2025-08-12T18:36:16.160447Z","shell.execute_reply.started":"2025-08-12T18:36:15.927335Z","shell.execute_reply":"2025-08-12T18:36:16.159557Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Module 4: Data transformations - demonstrating Log transformation\nPackages used: matplotlib, seaborn, scipy.stats\n\nDataset: heart-disease-uci/heart.csv","metadata":{}},{"cell_type":"code","source":"#Loading data\ndc=pd.read_csv(\"/kaggle/input/heart-disease-data/heart_disease_uci.csv\")\n\n#Plotting the original cholestrol distribution data\nsns.displot(dc[\"chol\"],kde=True)\nplt.title(\"DISTRIBUTION OF CHOLESTROL LEVEL\",fontsize=20)\nskewness=str(dc[\"chol\"].skew()) #measures the skewness\nkurtosis=str(dc[\"chol\"].kurt())\nplt.legend([skewness,kurtosis],title=(\"skewness and kurtosis\"))\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:16.161486Z","iopub.execute_input":"2025-08-12T18:36:16.161781Z","iopub.status.idle":"2025-08-12T18:36:16.516024Z","shell.execute_reply.started":"2025-08-12T18:36:16.161755Z","shell.execute_reply":"2025-08-12T18:36:16.515166Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Assignment Exercises\n\n* Complete the six exercises given above as comments in various code blocks.\n* Repeat (all or most or as appropriate) the above workbook steps for data engineering and visualization for the 'students-random-number-dataset' already linked to this notebook.\n* Plot the distributions discussed in class, other than gaussian and poisson.\n* For the dataset in CELL 30-31 above, apply other transformations (not the Log transform) discussed in class.\n\nSubmission steps: \n* Clone and Edit this notebook to add all new exercises below this cell.\n* Once finished, connect this notebook to github.\n* Using the assignment link, join the github classroom by connecting your github account with already available name roster containing your institute email.\n* Commit!","metadata":{}},{"cell_type":"code","source":"#Log transformation\nlog_target=np.log1p(dc[\"chol\"])\nax=sns.distplot(log_target)\nplt.title(\"DISTRIBUTION AFTER LOG TRANSFORMATION\",)\nskewness=str(log_target.skew())\nplt.legend([skewness],title=(\"skewness\"))\nplt.show()\n\n# Exercise 6: Repeat this for square root and other transformations.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:16.517102Z","iopub.execute_input":"2025-08-12T18:36:16.517309Z","iopub.status.idle":"2025-08-12T18:36:16.831031Z","shell.execute_reply.started":"2025-08-12T18:36:16.517293Z","shell.execute_reply":"2025-08-12T18:36:16.830215Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Exercise 6: \nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats import yeojohnson\n\n# Load dataset\ndc = pd.read_csv(\"/kaggle/input/heart-disease-data/heart_disease_uci.csv\")\n\n# Keep only finite numbers for transformations\nchol_clean = dc[\"chol\"].replace([np.inf, -np.inf], np.nan).dropna()\n\n# Square root transformation\nsqrt_target = np.sqrt(chol_clean)\nsns.histplot(sqrt_target, kde=True)\nplt.title(\"Square Root Transformation\")\nplt.show()\n\n# Yeo-Johnson transformation\nyj_target, _ = yeojohnson(chol_clean)\nsns.histplot(yj_target, kde=True)\nplt.title(\"Yeo-Johnson Transformation\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:16.832107Z","iopub.execute_input":"2025-08-12T18:36:16.832453Z","iopub.status.idle":"2025-08-12T18:36:17.793881Z","shell.execute_reply.started":"2025-08-12T18:36:16.832431Z","shell.execute_reply":"2025-08-12T18:36:17.792935Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Square Root Transformation\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Load dataset\ndc = pd.read_csv(\"/kaggle/input/heart-disease-data/heart_disease_uci.csv\")\n\n# Clean data: remove NaN and infinite values\nchol_clean = dc[\"chol\"].replace([np.inf, -np.inf], np.nan).dropna()\n\n# Apply square root transformation\nsqrt_target = np.sqrt(chol_clean)\n\n# Plot distribution\nsns.histplot(sqrt_target, kde=True)\nplt.title(\"Square Root Transformation of Cholesterol Levels\")\nplt.xlabel(\"Transformed Cholesterol\")\nplt.ylabel(\"Frequency\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:17.794711Z","iopub.execute_input":"2025-08-12T18:36:17.794987Z","iopub.status.idle":"2025-08-12T18:36:18.087337Z","shell.execute_reply.started":"2025-08-12T18:36:17.794965Z","shell.execute_reply":"2025-08-12T18:36:18.086465Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load dataset\ndf = pd.read_csv('/kaggle/input/students-random-number-dataset/stud-randnum-dataset.csv')\ndf.head() #preview first few rows to understand the structure\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:18.088339Z","iopub.execute_input":"2025-08-12T18:36:18.088640Z","iopub.status.idle":"2025-08-12T18:36:18.102638Z","shell.execute_reply.started":"2025-08-12T18:36:18.088613Z","shell.execute_reply":"2025-08-12T18:36:18.101784Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:18.103679Z","iopub.execute_input":"2025-08-12T18:36:18.104294Z","iopub.status.idle":"2025-08-12T18:36:18.113984Z","shell.execute_reply.started":"2025-08-12T18:36:18.104265Z","shell.execute_reply":"2025-08-12T18:36:18.113126Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:18.115036Z","iopub.execute_input":"2025-08-12T18:36:18.115612Z","iopub.status.idle":"2025-08-12T18:36:18.130426Z","shell.execute_reply.started":"2025-08-12T18:36:18.115588Z","shell.execute_reply":"2025-08-12T18:36:18.129381Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df.isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:18.131457Z","iopub.execute_input":"2025-08-12T18:36:18.131788Z","iopub.status.idle":"2025-08-12T18:36:18.148623Z","shell.execute_reply.started":"2025-08-12T18:36:18.131760Z","shell.execute_reply":"2025-08-12T18:36:18.147739Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df.duplicated())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:18.149603Z","iopub.execute_input":"2025-08-12T18:36:18.149942Z","iopub.status.idle":"2025-08-12T18:36:18.169592Z","shell.execute_reply.started":"2025-08-12T18:36:18.149914Z","shell.execute_reply":"2025-08-12T18:36:18.168648Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df.describe(include='all'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:18.170660Z","iopub.execute_input":"2025-08-12T18:36:18.171356Z","iopub.status.idle":"2025-08-12T18:36:18.195475Z","shell.execute_reply.started":"2025-08-12T18:36:18.171325Z","shell.execute_reply":"2025-08-12T18:36:18.194476Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df.dtypes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:18.196435Z","iopub.execute_input":"2025-08-12T18:36:18.196779Z","iopub.status.idle":"2025-08-12T18:36:18.202296Z","shell.execute_reply.started":"2025-08-12T18:36:18.196748Z","shell.execute_reply":"2025-08-12T18:36:18.201451Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Square Root Transformation\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Load dataset\ndc = pd.read_csv(\"/kaggle/input/heart-disease-data/heart_disease_uci.csv\")\n\n# Clean data: remove NaN and infinite values\nchol_clean = dc[\"chol\"].replace([np.inf, -np.inf], np.nan).dropna()\n\n# Apply square root transformation\nsqrt_target = np.sqrt(chol_clean)\n\n# Plot distribution\nsns.histplot(sqrt_target, kde=True)\nplt.title(\"Square Root Transformation of Cholesterol Levels\")\nplt.xlabel(\"Transformed Cholesterol\")\nplt.ylabel(\"Frequency\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:18.203165Z","iopub.execute_input":"2025-08-12T18:36:18.203398Z","iopub.status.idle":"2025-08-12T18:36:18.480433Z","shell.execute_reply.started":"2025-08-12T18:36:18.203380Z","shell.execute_reply":"2025-08-12T18:36:18.479544Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Square Root Transformation for dataset in Cell 30-31\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Load dataset\ndc = pd.read_csv(\"/kaggle/input/heart-disease-data/heart_disease_uci.csv\")\n\n# Clean the 'chol' column: remove NaN and infinite values\nchol_clean = dc[\"chol\"].replace([np.inf, -np.inf], np.nan).dropna()\n\n# Apply square root transformation\nsqrt_target = np.sqrt(chol_clean)\n\n# Plot\nsns.histplot(sqrt_target, kde=True)\nplt.title(\"Square Root Transformation of Cholesterol Levels\")\nplt.xlabel(\"Transformed Cholesterol\")\nplt.ylabel(\"Frequency\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:36:18.481422Z","iopub.execute_input":"2025-08-12T18:36:18.482231Z","iopub.status.idle":"2025-08-12T18:36:18.754661Z","shell.execute_reply.started":"2025-08-12T18:36:18.482206Z","shell.execute_reply":"2025-08-12T18:36:18.753710Z"}},"outputs":[],"execution_count":null}]}